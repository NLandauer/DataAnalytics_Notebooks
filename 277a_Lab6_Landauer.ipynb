{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9081cdf1-aeee-489c-90e0-e8bd5107fd08",
   "metadata": {},
   "source": [
    "### Noelle Landauer\n",
    "CIS 277A, Lab 6, 11/8/22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7870816-0490-4764-adb5-9383aee09ccc",
   "metadata": {},
   "source": [
    "## Bumblebee species in Oregon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e40c36-d36c-442d-92d2-792eab833d7e",
   "metadata": {},
   "source": [
    "Original sources of [2018](https://www.gbif.org/dataset/b2974853-6c41-4c63-a11b-7989e58a3ad4) and [2019](https://www.gbif.org/dataset/3301620d-6750-434e-97ad-abfac165bb9c) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41db0b7-07a7-42b5-b806-646c71d8b8d5",
   "metadata": {},
   "source": [
    "To keep the imported files to more managable size, this week I will focus on Oregon's bumblebees (genus Bombus). I have two pools of data to combine together, from 2018 and 2019. To simplfy data cleanup, I eliminated unneeded columns and filtered rows to only include genus Bombus in the original Excel files. First, we need to import each dataset into a Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df67b856-da27-4f94-9554-33eb6c976f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66144b0b-9b57-44fc-b6d9-3b24b42116e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\noell\\\\OneDrive\\\\Documents\\\\Classes\\\\CIS277A_DataAnalytics\\\\277A_Lab6_NoelleLandauer\\\\Bombus2018.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bombus18 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mnoell\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mOneDrive\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDocuments\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mClasses\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mCIS277A_DataAnalytics\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m277A_Lab6_NoelleLandauer\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mBombus2018.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m bombus19 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnoell\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mClasses\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCIS277A_DataAnalytics\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m277A_Lab6_NoelleLandauer\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBombus2019.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:457\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    456\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 457\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    460\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1376\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1376\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1380\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1381\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1250\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1248\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1252\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1253\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1254\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:795\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    786\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    787\u001b[0m             handle,\n\u001b[0;32m    788\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    791\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    792\u001b[0m         )\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 795\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    798\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\noell\\\\OneDrive\\\\Documents\\\\Classes\\\\CIS277A_DataAnalytics\\\\277A_Lab6_NoelleLandauer\\\\Bombus2018.xlsx'"
     ]
    }
   ],
   "source": [
    "bombus18 = pd.read_excel(r\"C:\\Users\\noell\\OneDrive\\Documents\\Classes\\CIS277A_DataAnalytics\\277A_Lab6_NoelleLandauer\\Bombus2018.xlsx\")\n",
    "bombus19 = pd.read_excel(r\"C:\\Users\\noell\\OneDrive\\Documents\\Classes\\CIS277A_DataAnalytics\\277A_Lab6_NoelleLandauer\\Bombus2019.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ea87c4-7924-4035-b517-b20945c17438",
   "metadata": {},
   "source": [
    "Let's take a look at the columns of each Dataframe to make sure they are reasonably aligned for merging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88077ecb-7ab2-42e7-879b-1b9c41c06c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "bombus18.info()\n",
    "bombus19.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2414c725-58d0-498e-b099-e156075ed08e",
   "metadata": {},
   "source": [
    "The longitude, latitude, and day/month/year have datatype float in 2018, int in 2019. This will resolve to float when the columns merge, so I'm not going to worry about it now. Otherwise the columns between the two Dataframes look compatible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ed8cdc-f8ae-4373-b47d-5c6a894b7baa",
   "metadata": {},
   "source": [
    "Since each row in both Dataframes represents a separate bee, we want all the rows of one dataset added to the bottom of the other dataset, rather than joining rows. So we will concantenate the two Dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33742b36-6b5e-4d10-80c4-2894871ce489",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bombus = pd.concat([bombus18, bombus19], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375e8299-5404-4dd3-985e-7c751c5661be",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bombus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b03a554-eb4d-4bb3-bf3c-9d908e4284be",
   "metadata": {},
   "source": [
    "By scrolling over the dates. I can see that the 2018 rows are at the top, and 2019 at the bottom. I can also see a few rows at the top where the species has not been determined, so let's see how many:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43047f8d-0c7d-4a47-a92b-3569ca465129",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_count = all_bombus.shape[0] - all_bombus.count()\n",
    "print(missing_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cf5218-bc09-4d2c-94c7-26a56e147d26",
   "metadata": {},
   "source": [
    "Since there are only 17 missing species determinations and 1 missing date out of nearly 5000 rows, I'm going to remove them from the set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41872ba-1481-48f5-98b3-074492c6c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bombus = all_bombus.dropna()\n",
    "missing_count = all_bombus.shape[0] - all_bombus.count()\n",
    "print(missing_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf14caa1-d421-4ec2-8b1d-59ce41d2869d",
   "metadata": {},
   "source": [
    "Next let's reset the index. There are two columns with unique identifying rows to potentially use as a key. One is the GBIF database identifier (gbifID), the other is the Oregon State Arthropod Collection url (occurenceID), which contains either an OBA or OSAC number embedded in a string. Since the occurenceID is more complex than is necessary for this task, I'll use the gbifID for the Dataframe index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f67e28-c621-44cc-8adc-c048fd6a80d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bombus.set_index('gbifID', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb99edd6-7717-45b0-9c6c-00204f6c6ec9",
   "metadata": {},
   "source": [
    "Next I want to take a look at the data grouped by species and year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf8abe0-2e6f-4ca2-af1e-bf4e4820ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "bombus_species_by_year = pd.crosstab(all_bombus['species'],all_bombus['year'].astype('int'))\n",
    "bombus_species_by_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338d2e6c-f60f-408e-a121-067701628934",
   "metadata": {},
   "source": [
    "A handful of bees were apparently collected in 2017, but since they have location and date data I'll leave them for now. More concerning are values of 0 under B. bifarius (2019) and B. vancouverensis (2018), which is a bit strange for relatively numerous bees. A little bit of internet [sleuthing](https://washingtonbumblebees.org/bumblebee-field-id/no-red-yes-stripes/two-form-bumble-bee-bombus-bifarius/) reveals that the species identification of B. bifarius west of the Rockies has been hotly debately for years, as it has distinct coloration compared to its eastern counterparts and similarities to B. vancouverensis, found on its namesake island. A recent genetic analysis found gene flow between the bifarius and vancouverensis populations, so now all western bifarius bees are being [rolled over](https://bugguide.net/node/view/184373) into vancouverensis. (Taxonomy!) So I will update the all_bombus and bombus_species_by_year Dataframes to reflect this change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8caf14-4a64-4b03-b809-334e28f47933",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bombus = all_bombus.replace(to_replace='Bombus bifarius', value='Bombus vancouverensis')\n",
    "bombus_species_by_year = pd.crosstab(all_bombus['species'],all_bombus['year'].astype('int'))\n",
    "bombus_species_by_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d142865a-f1ea-4f34-a12c-a2bcc7199d99",
   "metadata": {},
   "source": [
    "Finally, let's get a total count of each species in Oregon to see the both the rarest and most common species. Using this data for population numbers is a bit tricky, as the Oregon Bee Atlas data is biased towards diversity and rarer bees. The more common species are not collected in proportion to their (large) numbers; instead a few are caught at each site to indicate their presence, not a absolute count. But we can still get an idea that some species are extremely widespread while others are rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb11a7-b2bb-4e7b-b51f-6e9c95dca0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bombus_species = all_bombus['species'].value_counts()\n",
    "bombus_species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452f2eae-5c8f-497b-8e7a-775840d519f5",
   "metadata": {},
   "source": [
    "Same data, plotted in a bar graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73e7a46-af99-419c-9e1e-1b3d8a2b8f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "bombus_species.plot.barh(\n",
    "    title='Bumblebee species frequency in the Oregon Bee Atlas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5328363-1644-43cf-ab45-6787eeb262e2",
   "metadata": {},
   "source": [
    "## Have IMDB ratings changed over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2d17ff-392f-4f1f-985e-87e84a18fb19",
   "metadata": {},
   "source": [
    "Connection object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cfc3c8-a9d0-4ab6-95d8-08f0c6e7315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pyodbc.connect(\n",
    "    server=\"cisdbss.pcc.edu\",\n",
    "    user=\"275student\",\n",
    "    password=\"275student\",\n",
    "    database=\"IMDB\",\n",
    "    driver=\"{ODBC Driver 17 for SQL Server}\")\n",
    "\n",
    "connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a49151a-cb1a-439f-a868-f075a7e9d850",
   "metadata": {},
   "source": [
    "SQL query to retrieve all movies with at least 5000 votes and their ratings from the IMDB database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1de9008-47e4-4f6a-9bdf-773952d9f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''SELECT primaryTitle, tb.tconst, startYear, averageRating, numVotes\n",
    "FROM title_basics tb\n",
    "JOIN title_ratings tr ON tb.tconst=tr.tconst\n",
    "WHERE titleType = 'movie'\n",
    "AND numVotes > 5000\n",
    "AND isAdult = 0;'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527362ad-8096-494f-8a87-0061b47bdb1e",
   "metadata": {},
   "source": [
    "Query database and place in a Dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860fd0b5-8c60-4946-ac49-6d7e81febe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings = pd.read_sql_query(sql, connection)\n",
    "movie_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15a15c3-1ac7-48e8-9b8f-117d463da18d",
   "metadata": {},
   "source": [
    "Set the index to tconst, since it was already conveniently set up as a key in the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae62a48e-0c29-4570-86c8-9491bfbf5616",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings.set_index('tconst', inplace=True)\n",
    "movie_ratings.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84f83d3-c629-4ae8-aa9d-459687bd95a1",
   "metadata": {},
   "source": [
    "Let's look at average rating per year to start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16316904-13fb-4cc3-8a59-f877ece87d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rating_by_year = movie_ratings.groupby('startYear').mean()\n",
    "avg_rating_by_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db84e24-3b0b-4641-903f-ad3cbf1709e3",
   "metadata": {},
   "source": [
    "Plot over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eea1d4f-3606-4985-b50e-8d75b2e2a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_ratings_plot = sns.lineplot(data=avg_rating_by_year, x='startYear', y='averageRating')\n",
    "year_ratings_plot.annotate(text='IMDB founded', \n",
    "                           xy=(1990, 6.6), \n",
    "                           xytext=(1991, 6.8), \n",
    "                           arrowprops=dict(facecolor='red', width=3, headwidth=12, headlength=6)\n",
    "                          )\n",
    "year_ratings_plot.set(title='Average movie rating per year')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c14586-b3f0-4d9d-ba4e-81a20782af8f",
   "metadata": {},
   "source": [
    "We could hypothesize that only more well-known movies prior to IMDB's founding in 1990 receive more than 5000 votes, and this biases the older movie's ratings. How many movies received more than 5000 votes per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953c5cb7-e52f-45c5-ace2-9b54f93e989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_count_by_year = movie_ratings.groupby('startYear').count()\n",
    "count_plot = sns.lineplot(data=movie_count_by_year, x='startYear', y='numVotes')\n",
    "count_plot.set(title='Number of movies with at least 5000 votes per year')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db463a1-45ef-40e8-81c8-cd5c9612b8c8",
   "metadata": {},
   "source": [
    "And are the number of votes changing over time as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508aea6f-88f2-4f02-a796-495e70757935",
   "metadata": {},
   "outputs": [],
   "source": [
    "numvotes_plot = sns.lineplot(data=avg_rating_by_year, x='startYear', y='numVotes')\n",
    "numvotes_plot.set(title='Average number of votes per year (minimum 5000)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5251af-9d6e-4cd4-94dd-dbe5d41fe38a",
   "metadata": {},
   "source": [
    "It looks like the number of votes are increasing, but there is a lot of fluctuation from year to year. Perhaps if we create bins for years and the number of votes, the pattern may be clearer. The year groupings are a bit arbitrary, but I wanted to capture the three phases of the \"average movie rating per year\" graph: high early ratings, dropoff in the 70s-80s, post-IMDB. Since numVotes has a lot of variation, with a few movies on the tail end with very high number of votes, I used quintiles for these bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade0bc56-5e7c-42c4-b0ed-87384071b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_bins = [1915, 1960, 1990, 2018]\n",
    "movie_ratings['YearGroup'] = pd.cut(movie_ratings['startYear'], \n",
    "                                    bins=year_bins, \n",
    "                                    labels=['Premodern', 'Early Modern', 'IMDB Era'])\n",
    "movie_ratings['numVotesQuintiles'] = pd.qcut(movie_ratings['numVotes'], q=5)\n",
    "movie_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a33739-0b5b-4913-94bc-7e7fdde25425",
   "metadata": {},
   "source": [
    "Let's look at a pivot table of averageRating across the bins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab0029e-c589-48f2-beeb-e4af011fccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_by_bin = movie_ratings.pivot_table(index='numVotesQuintiles',\n",
    "                                           columns='YearGroup',\n",
    "                                           values='averageRating',\n",
    "                                           aggfunc='mean')\n",
    "ratings_by_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f38439a-3ab9-4c8d-b00f-4beeca890b37",
   "metadata": {},
   "source": [
    "Same data graphed out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96966ed-1d70-4879-8d11-16bf0c96c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_bin_barplot = sns.catplot(data=movie_ratings, \n",
    "                                  kind='bar', \n",
    "                                  x='YearGroup', \n",
    "                                  y='averageRating', \n",
    "                                  hue='numVotesQuintiles',\n",
    "                                  ci=None)\n",
    "ratings_bin_barplot.set(ylim=(5,8.5), \n",
    "                        title='Average movie rating by era and number of votes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bd3e38-536d-4c50-8199-880ea6e44b3a",
   "metadata": {},
   "source": [
    "It seems clear that, although there is a positive correlation between number of votes and average rating, the premodern era still has systematically higher ratings across the board, while the IMDB era -- with many more movies being rated -- has lower average ratings."
   ]
  },
  {
   "cell_type": "raw",
   "id": "cdd322ba-9824-4217-9f0a-f7c21f34a0f3",
   "metadata": {},
   "source": [
    "<seaborn.axisgrid.FacetGrid at 0x1dded0cff40>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
